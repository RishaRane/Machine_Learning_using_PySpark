{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef86553c",
   "metadata": {},
   "source": [
    "# Tutorial 4 : Data Cleaning using PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92d9af81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afb2b7a",
   "metadata": {},
   "source": [
    "### 1. Starting the spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e3c1567",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 20:17:00 WARN Utils: Your hostname, Rishas-MacBook-Air.local resolves to a loopback address: 127.0.0.1; using 192.168.45.141 instead (on interface en0)\n",
      "24/09/14 20:17:00 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/09/14 20:17:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('data_cleaning_session').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b383860b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.45.141:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>data_cleaning_session</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f812a476a10>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba52ec0",
   "metadata": {},
   "source": [
    "### 2. Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a893f387",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('demo_data.csv', header = True, inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bd90244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------------------+------+\n",
      "|Degree| Age|Experience (in years)|Salary|\n",
      "+------+----+---------------------+------+\n",
      "|    BE|  25|                    0|     0|\n",
      "|    BE|  27|                    2| 15000|\n",
      "|    ME|  34|                    7| 50000|\n",
      "|   BBA|  26|                    1|  1000|\n",
      "|  NULL|  24|                    1| 15000|\n",
      "|   BSC|NULL|                    4| 20000|\n",
      "|   MSC|  31|                    6| 45000|\n",
      "| Mtech|NULL|                    3|  NULL|\n",
      "|    BE|  28|                 NULL| 13500|\n",
      "+------+----+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5338d7e8",
   "metadata": {},
   "source": [
    "### 3. Check for null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd87d06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------------------+------+\n",
      "|Degree|Age|Experience (in years)|Salary|\n",
      "+------+---+---------------------+------+\n",
      "|     1|  2|                    1|     1|\n",
      "+------+---+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, when, count\n",
    "\n",
    "df.select([count(when(col(c).isNull(), c)).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7fd0ece7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Degree: string (nullable = true)\n",
      " |-- Age: integer (nullable = true)\n",
      " |-- Experience (in years): integer (nullable = true)\n",
      " |-- Salary: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c6d8018e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a copy of main df\n",
    "df1 = df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f96b3cf",
   "metadata": {},
   "source": [
    "**Method 1 - Dropping all Null Values**|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a29c0602",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b9c89d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------------------+------+\n",
      "|Degree|Age|Experience (in years)|Salary|\n",
      "+------+---+---------------------+------+\n",
      "|     0|  0|                    0|     0|\n",
      "+------+---+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df1.select([count(when(col(c).isNull(), c)).alias(c) for c in df1.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5506761e",
   "metadata": {},
   "source": [
    "**Method 2 - Dropping Null Values from specific columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b8ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df\n",
    "\n",
    "df2 = df2.na.drop(subset = ['Degree']) #Only the row with null value in Degree col will be dropped "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3f962741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+---+---------------------+------+\n",
      "|Degree|Age|Experience (in years)|Salary|\n",
      "+------+---+---------------------+------+\n",
      "|     0|  2|                    1|     1|\n",
      "+------+---+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2.select([count(when(col(c).isNull(), c)).alias(c) for c in df2.columns]).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a431531",
   "metadata": {},
   "source": [
    "**Method 3 - Substituting the values for NULL data**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705edf18",
   "metadata": {},
   "source": [
    "**3.1 For string**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f1bc0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df\n",
    "\n",
    "df3 = df3.fillna('Missing')  #df3 = df3.na.fill('Missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c8b04ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----+---------------------+------+\n",
      "| Degree| Age|Experience (in years)|Salary|\n",
      "+-------+----+---------------------+------+\n",
      "|     BE|  25|                    0|     0|\n",
      "|     BE|  27|                    2| 15000|\n",
      "|     ME|  34|                    7| 50000|\n",
      "|    BBA|  26|                    1|  1000|\n",
      "|Missing|  24|                    1| 15000|\n",
      "|    BSC|NULL|                    4| 20000|\n",
      "|    MSC|  31|                    6| 45000|\n",
      "|  Mtech|NULL|                    3|  NULL|\n",
      "|     BE|  28|                 NULL| 13500|\n",
      "+-------+----+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb18808",
   "metadata": {},
   "source": [
    "**3.2 For integer - Filling all null values with constant value**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4802f66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df3.na.fill(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70e1a73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+---------------------+------+\n",
      "| Degree|Age|Experience (in years)|Salary|\n",
      "+-------+---+---------------------+------+\n",
      "|     BE| 25|                    0|     0|\n",
      "|     BE| 27|                    2| 15000|\n",
      "|     ME| 34|                    7| 50000|\n",
      "|    BBA| 26|                    1|  1000|\n",
      "|Missing| 24|                    1| 15000|\n",
      "|    BSC|  0|                    4| 20000|\n",
      "|    MSC| 31|                    6| 45000|\n",
      "|  Mtech|  0|                    3|     0|\n",
      "|     BE| 28|                    0| 13500|\n",
      "+-------+---+---------------------+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9e36a8",
   "metadata": {},
   "source": [
    "**3.3 For interger - Inputation (Filling the null value with statistic of that column)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9daff90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df\n",
    "\n",
    "num_cols = [col_name for col_name, data_type in df4.dtypes if 'int' in data_type]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c26390e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Age', 'Experience (in years)', 'Salary']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cccf29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Imputer\n",
    "\n",
    "imputer = Imputer(inputCols = num_cols,\n",
    "                 outputCols = [col_name + '_imp' for col_name in num_cols],\n",
    "                 strategy = 'mean')\n",
    "\n",
    "df4 = imputer.fit(df4).transform(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4d460c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+---------------------+------+-------+-------------------------+----------+\n",
      "|Degree| Age|Experience (in years)|Salary|Age_imp|Experience (in years)_imp|Salary_imp|\n",
      "+------+----+---------------------+------+-------+-------------------------+----------+\n",
      "|    BE|  25|                    0|     0|     25|                        0|         0|\n",
      "|    BE|  27|                    2| 15000|     27|                        2|     15000|\n",
      "|    ME|  34|                    7| 50000|     34|                        7|     50000|\n",
      "|   BBA|  26|                    1|  1000|     26|                        1|      1000|\n",
      "|  NULL|  24|                    1| 15000|     24|                        1|     15000|\n",
      "|   BSC|NULL|                    4| 20000|     27|                        4|     20000|\n",
      "|   MSC|  31|                    6| 45000|     31|                        6|     45000|\n",
      "| Mtech|NULL|                    3|  NULL|     27|                        3|     19937|\n",
      "|    BE|  28|                 NULL| 13500|     28|                        3|     13500|\n",
      "+------+----+---------------------+------+-------+-------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1bcbcf31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/09/14 20:26:12 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+------------------+---------------------+------------------+------------------+-------------------------+------------------+\n",
      "|summary|Degree|               Age|Experience (in years)|            Salary|           Age_imp|Experience (in years)_imp|        Salary_imp|\n",
      "+-------+------+------------------+---------------------+------------------+------------------+-------------------------+------------------+\n",
      "|  count|     8|                 7|                    8|                 8|                 9|                        9|                 9|\n",
      "|   mean|  NULL|27.857142857142858|                  3.0|           19937.5|27.666666666666668|                      3.0|19937.444444444445|\n",
      "| stddev|  NULL| 3.532165125838609|   2.5071326821120348|18432.187491295917| 3.082207001484489|        2.345207879911715| 17241.73262110794|\n",
      "|    min|   BBA|                24|                    0|                 0|                24|                        0|                 0|\n",
      "|    max| Mtech|                34|                    7|             50000|                34|                        7|             50000|\n",
      "+-------+------+------------------+---------------------+------------------+------------------+-------------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "65e7689f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the previous columns with null values\n",
    "df4 = df4.drop(*num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9eb88076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-------+-------------------------+----------+\n",
      "|Degree|Age_imp|Experience (in years)_imp|Salary_imp|\n",
      "+------+-------+-------------------------+----------+\n",
      "|    BE|     25|                        0|         0|\n",
      "|    BE|     27|                        2|     15000|\n",
      "|    ME|     34|                        7|     50000|\n",
      "|   BBA|     26|                        1|      1000|\n",
      "|  NULL|     24|                        1|     15000|\n",
      "|   BSC|     27|                        4|     20000|\n",
      "|   MSC|     31|                        6|     45000|\n",
      "| Mtech|     27|                        3|     19937|\n",
      "|    BE|     28|                        3|     13500|\n",
      "+------+-------+-------------------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ff203d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
